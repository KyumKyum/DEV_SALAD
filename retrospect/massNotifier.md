# 대용량 알림 처리 서버 개발 회고록

### 의의
- 메세지 큐와 이벤트 스트리밍 구조를 활용한 대용량 트래픽 처리 서비스 개발 경험
- 분산 클러스터 환경에서의 중복 / 연속성 문제
---
### 배경
- 현재 개발하고 있는 '대용량 알림 서비스'는 다음과 같은 조건으로 개발되고 있다.
    1. 초당 적게는 만 건, 많게는 백만 건의 요청을 감당할 수 있는 서비스.    
    2. 기술 교체가 쉬운 서비스 (MVP는 Redis, RabbitMQ로 개발하지만, 나중에는 Apache Kafka로 교체하기 쉽도록)

- 1번과 같은 경우는, 이벤트 스트리밍 구조와 Fire & Forget전략을 취하여 해결을 하였다.
- 2번과 같은 경우는, Core Manager와 Core Provider를 모듈화하여 해결을 하였다.

- 그리고 다음과 같은 추가적인 전략도 취했다.
    1. Stash & Flush 전략: 알림의 내용이 너무 긴 경우, 이를 '이벤트'라는 단위로 나누어 처리를 한 뒤, 나중에 한번에 다시 직렬화 (Serialization)을 하여 전송을 한다.
        - Queue는 순서가 보장되기에, 여러개의 이벤트로 이루어진 알림의 경우, 일단 이벤트들을 저장하고 (Stash), '마침'을 알리는 이벤트가 오면 다시 불러와서 (Flush) 직렬화후 처리하는 전략을 취했다.

- 테스트도 순조로웠다. 하지만 큰 문제가 발생했다.
---
### 문제상황
- **분산 클러스터 환경을 생각하지 못했다.**
- 순간 머릿속에 들어온 '분산 클러스터 환경'은 분명 내가 고려하지 못한 부분이었다.
- 곧바로 pm2로 인스턴스 3개를 만들어 테스트 환경을 만들어봤고, 요청을 보내자 예상했던대로 다음과 같은 문제가 발생했다.
    1. **Race Condition**
        - 서버는 여러대가 되었지만, 캐시는 1개이다. 데이터의 연속성을 지키기 위해서 각 서버가 해당 cache에 접근하는 순서와 조건이 제한이 되어야하지만, 그런 것이 전혀 없었다.
    2. **중복 요청**
        - 애초에 요청이 1개를 보냈는데, 인스턴스의 수만큼의 요청이 보내진다는 것은, 각 replica set이 요청을 받아온다는 것이고, 이것이 아마 분산 클러스터 환경에서 엉망진창이 되는 문제일 것이다.
    3. **Shared Cache**
        - Stash & Flush가 일어나는 캐시의 경우, 스케일 아웃이 어렵다는 문제도 존재한다. 데이터베이스 샤딩과 비슷한 문제이고, 이를 위해 샤딩 프로세스를 구현하기 위해 Hash Ring을 구현하는 것은 오버 엔지니어링일 것이다. 
        - 결국 해당 캐시는 공유가 되는 하나의 캐시여야할텐데, 과연 최대 100만건의 요청을 해당 캐시가 버틸 수 있을지는 의문이다.
---
### 진행 방향
- 다음과 같은 진행 방향을 갖기로 한다.

1. Bulk Consume 방법으로 결정.(설명 추가)

2. Load Balancer
- 실재 개발 환경에서 Ingress를 달면 된다고 막연하게 생각하고 있었는데, 중복 요청은 아무리 봐도 Load Balancer가 없어서 생기는 문제인 것 같다. 간단하게 Nginx하나 달아서 이걸로 중복 요청이 해결이 되는지, 분산 환경에서 추가적인 문제는 없는지 확인해봐야겠다.