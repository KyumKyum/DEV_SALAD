# 대용량 알림 처리 서버 개발 회고록 4: Rate Limit

### 개요 (TL;DR)
#### 개발한 것: 대형 알림 처리 마이크로 서비스 (TPS 10K ~ 1M)
- 메세지 큐와 이벤트 스트리밍 구조를 활용한 대용량 트래픽 처리 서비스 개발 경험
#### 목표
- DoS 공격 및 부하완화를 위한 Rate Limit 구현.
#### 해결 방법: 
- Token Bucket 기반의 설계와 Redis를 활용하여 구현.
---
### 배경
- 문제는 해결이 되었으니, 이제는 배포 준비를 위한 준비를 한다. 그 중 첫번째는 **Rate Limiting**이다.
    - 마이크로 서비스로 사용되는 대용량 알림 처리 서버 특성상, 특정 기간에 트래픽이 몰리는 것을 상정하고 만들고 있다. 해당 서비스를 사용하는 서비스는 알려지지 않은 사용자가 아닌, 알려진 사내 서비스들이고, 그 서비스들도 이를 고려하여 "예의있게" 요청을 날려줄 것이다.
    - 하지만 언제나 예외 케이스는 존재하는 법. 서비스의 수는 늘어날 것이고, 늘어난 서비스가 한 번에 요청을 보내는 케이스도 있을 것이다. 더군다나, 이런 "예의 없는" 요청을 제외하고도 DoS공격과 같은 것을 대비하여, 요청의 임계치를 정할 필요성이 있다.
    - 서비스의 가용성과 안정성, 보안 등등의 목적을 가지고 Rate Limit을 구현한다.

### 진행 방향
**1. Rate Limit의 방법: Throttling**
- 요청의 수가 임계치를 넘었을 때, `Retry-After`정보를 헤더에 넣어서 `429 (Too Many Requests)`응답을 반환해준다.
    - 임계치를 어느 정도 넘어도 되는 Soft Throttling, Elastic Throttling과는 달리, 나는 일단은 Hard Throttling으로 개발을 진행할 것이다. 현재 개발 단계에서는 요청을 받은 이후의 Redis 메세지 큐가 곧 SPOF이기에, 현재로서는 조금 더 엄격히 제한할 필요가 있다.

**2. Rate Limit의 설계: Global Token Bucket**
- 일정 시간 동안 들어오는 API 요청에 대해서 총 요청 허용 수를 지정한다. (예: 1초에 1000개의 요청)
- 1초마다 1000개의 토큰이 새로 발급이 되고, 하나의 요청은 하나의 토큰을 소비한다. 토큰을 소비한 요청은 허용을 하여 메세지 큐로 넘긴다 (`201 (Created)`) 
- 만약 요청에 대한 토큰을 모두 소진한 경우 (1초에 1000개 이상의 토큰이 발급될 경우), 해당 요청부터는 Throttling을 건다. (`429 (Too Many Requests)`) 
    - 메세지 큐는 일정 시간마다 들어오는 허용된 요청 수만 감당하면 될 것이다. :)

**3. Rate Limit의 기술 스택: Redis**
- ~~이 정도면 나 Redis 정말 좋아하는 듯~~
- `DECR`, `SET`와 같이 atomicy가 보장이 되는 method를 사용하여 구현한다.
    - 일정 시간마다 `SET`을 통해 토큰을 새로 발급한다.
    - 매 요청마다 `DECR`을 통해 토큰을 소비한다.
        - `DECR`의 결과가 0보다 적다면, 토큰을 모두 소비하였다는 의미임으로 throttling을 건다.

---
### 결과
- Rate Limit을 구현 완료 하였고, 이에 맞추어 fallback logic도 수정하였다.
- Jmeter를 통해서 50000요청을 보냈고, 꾸준히 초당 설정한 요청만 수행을 하고, limit을 넘어가는 요청은 `429`가 반환되는 것을 확인하였다. 😎😎

